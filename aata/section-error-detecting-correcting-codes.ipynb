{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"http://mathbook.pugetsound.edu/beta/mathbook-content.css\" rel=\"stylesheet\" type=\"text/css\" />\n<link href=\"https://aimath.org/mathbook/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text/css\" />\n<style>.subtitle {font-size:medium; display:block}</style>\n<link href=\"https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text/css\" />\n<link href=\"https://fonts.googleapis.com/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text/css\" /><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code</button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n</script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\identity}{\\mathrm{id}}\n\\newcommand{\\notdivide}{\\nmid}\n\\newcommand{\\notsubset}{\\not\\subset}\n\\newcommand{\\lcm}{\\operatorname{lcm}}\n\\newcommand{\\gf}{\\operatorname{GF}}\n\\newcommand{\\inn}{\\operatorname{Inn}}\n\\newcommand{\\aut}{\\operatorname{Aut}}\n\\newcommand{\\Hom}{\\operatorname{Hom}}\n\\newcommand{\\cis}{\\operatorname{cis}}\n\\newcommand{\\chr}{\\operatorname{char}}\n\\newcommand{\\Null}{\\operatorname{Null}}\n\\newcommand{\\lt}{<}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h2 class=\"heading hide-type\" alt=\"Section 8.1 Error-Detecting and Correcting Codes\"><span class=\"type\">Section</span><span class=\"codenumber\">8.1</span><span class=\"title\">Error-Detecting and Correcting Codes</span></h2><a href=\"section-error-detecting-correcting-codes.ipynb\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1199\">Let us examine a simple model of a communications system for transmitting and receiving coded messages (Figure <a href=\"section-error-detecting-correcting-codes.ipynb#figure-encoding\" class=\"xref\" alt=\"Figure 8.1 \" title=\"Figure 8.1 \">8.1</a>).</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"figure-encoding\"><img src=\"images/algcodes-encode-decode.svg\" width=\"60%\" alt=\"\" /><figcaption><span class=\"type\">Figure</span><span class=\"codenumber\">8.1</span>Encoding and decoding messages</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1200\">Uncoded messages may be composed of letters or characters, but typically they consist of binary $m$-tuples. These messages are encoded into codewords, consisting of binary $n$-tuples, by a device called an <dfn class=\"terminology\">encoder</dfn>. The message is transmitted and then decoded. We will consider the occurrence of errors during transmission. An <dfn class=\"terminology\">error</dfn> occurs if there is a change in one or more bits in the codeword. A <dfn class=\"terminology\">decoding scheme</dfn> is a method that either converts an arbitrarily received $n$-tuple into a meaningful decoded message or gives an error message for that $n$-tuple. If the received message is a codeword (one of the special $n$-tuples allowed to be transmitted), then the decoded message must be the unique message that was encoded into the codeword. For received non-codewords, the decoding scheme will give an error indication, or, if we are more clever, will actually try to correct the error and reconstruct the original message. Our goal is to transmit error-free messages as cheaply and quickly as possible.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-repeat\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.2</span></h6><p id=\"p-1201\">One possible coding scheme would be to send a message several times and to compare the received copies with one another. Suppose that the message to be encoded is a binary $n$-tuple $(x_{1}, x_{2}, \\ldots, x_{n})\\text{.}$ The message is encoded into a binary $3n$-tuple by simply repeating the message three times:</p><div class=\"displaymath\">\n\\begin{equation*}\n(x_{1}, x_{2}, \\ldots, x_{n}) \\mapsto (x_{1}, x_{2}, \\ldots, x_{n}, x_{1}, x_{2}, \\ldots, x_{n}, x_{1}, x_{2}, \\ldots, x_{n}).\n\\end{equation*}\n</div><p>To decode the message, we choose as the $i$th digit the one that appears in the $i$th place in at least two of the three transmissions. For example, if the original message is $(0110)\\text{,}$ then the transmitted message will be $(0110\\;  0110\\;  0110)\\text{.}$ If there is a transmission error in the fifth digit, then the received codeword will be $(0110\\;  1110\\;  0110)\\text{,}$ which will be correctly decoded as $(0110)\\text{.}$<span class=\"footnote\"><a knowl=\"\" class=\"id-ref\" refid=\"hk-fn-2\" id=\"fn-2\"><sup> 2 </sup></a></span><span id=\"hk-fn-2\" class=\"hidden-content tex2jax_ignore\"><span class=\"footnote\">We will adopt the convention that bits are numbered left to right in binary $n$-tuples.</span></span>  This triple-repetition method will automatically detect and correct all single errors, but it is slow and inefficient: to send a message consisting of $n$ bits, $2n$ extra bits are required, and we can only detect and correct single errors. We will see that it is possible to find an encoding scheme that will encode a message of $n$ bits into $m$ bits with $m$ much smaller than $3n\\text{.}$</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-even-parity\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.3</span></h6><p id=\"p-1202\"><dfn class=\"terminology\">Even parity</dfn>, a  commonly  used coding scheme, is much more efficient than the simple repetition scheme. The <abbr class=\"acronym\">ASCII</abbr> (American Standard Code for Information Interchange) coding system uses binary 8-tuples, yielding $2^{8} = 256$ possible 8-tuples. However, only seven bits are needed since there are only $2^7 = 128$ <abbr class=\"acronym\">ASCII</abbr> characters. What can or should be done with the extra bit? Using the full eight bits, we can detect single transmission errors. For example, the <abbr class=\"acronym\">ASCII</abbr> codes for A, B, and C are</p><div class=\"displaymath\">\n\\begin{align*}\n\\text{A} & = 65_{10} = 01000001_{2},\\\\\n\\text{B} & = 66_{10} = 01000010_{2},\\\\\n\\text{C} & = 67_{10} = 01000011_{2}.\n\\end{align*}\n</div><p>Notice that the leftmost bit is always set to 0; that is, the 128 <abbr class=\"acronym\">ASCII</abbr> characters have codes</p><div class=\"displaymath\">\n\\begin{align*}\n00000000_{2} & = 0_{10},\\\\\n& \\vdots\\\\\n01111111_{2} & = 127_{10}.\n\\end{align*}\n</div><p>The bit can be used for error checking on the other seven bits. It is set to either 0 or 1 so that the total number of 1 bits in the representation of a character is even. Using even parity, the codes for A, B, and C now become</p><div class=\"displaymath\">\n\\begin{align*}\n\\text{A} & = 01000001_{2},\\\\\n\\text{B} & = 01000010_{2},\\\\\n\\text{C} & = 11000011_{2}.\n\\end{align*}\n</div><p>Suppose an A is sent and a transmission error in the sixth bit is caused by noise over the communication channel so that  $(0100\\; 0101)$ is received. We know an error has occurred since the received word has an odd number of 1s, and we can now request that the codeword be transmitted again. When used for error checking, the leftmost bit is called a <dfn class=\"terminology\">parity check bit</dfn>.</p><p id=\"p-1203\">By far the most common error-detecting codes used in computers are based on the addition of a parity bit. Typically, a computer stores information in $m$-tuples called <dfn class=\"terminology\">words</dfn>. Common word lengths are 8, 16, and 32 bits. One bit in the  word is set aside as the parity check bit, and is not used to store information. This bit is set to either 0 or 1, depending on the number of 1s in the word.</p><p id=\"p-1204\">Adding a parity check bit allows the detection of all single errors because changing a single bit either increases or decreases the number of 1s by one, and in either case the parity has been changed from even to odd, so the new word is not a codeword. (We could also construct an error detection scheme based on <dfn class=\"terminology\">odd parity</dfn>; that is, we could set the parity check bit so that a codeword always has an odd number of 1s.)</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1205\">The even parity system is easy to implement, but has two drawbacks. First, multiple errors are not detectable. Suppose an A is sent and  the first and seventh bits are changed from 0 to 1. The received word is a codeword, but will be decoded into a C instead of an A. Second, we do not have the ability to correct errors.  If the 8-tuple $(1001\\; 1000)$ is received, we know that an error has occurred, but we have no idea which bit has been changed. We will now investigate a coding scheme that will not only allow us to detect transmission errors but will actually correct the errors.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"table-repetition-code\"><table><tr><td class=\"c m b0 r0 l0 t2 lines\">Transmitted</td><td class=\"c m b0 r0 l0 t2 lines\" colspan=\"8\">Received Word</td></tr><tr><td class=\"c m b2 r0 l0 t0 lines\">Codeword</td><td class=\"c m b2 r0 l0 t0 lines\">000</td><td class=\"c m b2 r0 l0 t0 lines\">001</td><td class=\"c m b2 r0 l0 t0 lines\">010</td><td class=\"c m b2 r0 l0 t0 lines\">011</td><td class=\"c m b2 r0 l0 t0 lines\">100</td><td class=\"c m b2 r0 l0 t0 lines\">101</td><td class=\"c m b2 r0 l0 t0 lines\">110</td><td class=\"c m b2 r0 l0 t0 lines\">111</td></tr><tr><td class=\"c m b0 r0 l0 t0 lines\">000</td><td class=\"c m b0 r0 l0 t0 lines\">0</td><td class=\"c m b0 r0 l0 t0 lines\">1</td><td class=\"c m b0 r0 l0 t0 lines\">1</td><td class=\"c m b0 r0 l0 t0 lines\">2</td><td class=\"c m b0 r0 l0 t0 lines\">1</td><td class=\"c m b0 r0 l0 t0 lines\">2</td><td class=\"c m b0 r0 l0 t0 lines\">2</td><td class=\"c m b0 r0 l0 t0 lines\">3</td></tr><tr><td class=\"c m b2 r0 l0 t0 lines\">111</td><td class=\"c m b2 r0 l0 t0 lines\">3</td><td class=\"c m b2 r0 l0 t0 lines\">2</td><td class=\"c m b2 r0 l0 t0 lines\">2</td><td class=\"c m b2 r0 l0 t0 lines\">1</td><td class=\"c m b2 r0 l0 t0 lines\">2</td><td class=\"c m b2 r0 l0 t0 lines\">1</td><td class=\"c m b2 r0 l0 t0 lines\">1</td><td class=\"c m b2 r0 l0 t0 lines\">0</td></tr></table><figcaption><span class=\"type\">Table</span><span class=\"codenumber\">8.4</span>A repetition code</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-nearest\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.5</span></h6><p id=\"p-1206\">Suppose that our original message is either a 0 or a 1, and that 0 encodes to (000) and 1 encodes to (111). If only a single error occurs during transmission, we can detect and correct the error. For example, if a 101 is received, then the second bit must have been changed from a 1 to a 0.  The originally transmitted codeword must have been (111). This method will detect and correct  all single errors.</p><p id=\"p-1207\">In Table <a href=\"section-error-detecting-correcting-codes.ipynb#table-repetition-code\" class=\"xref\" alt=\"Table 8.4 \" title=\"Table 8.4 \">8.4</a>, we present all possible words that might be received for the transmitted codewords (000) and (111). Table <a href=\"section-error-detecting-correcting-codes.ipynb#table-repetition-code\" class=\"xref\" alt=\"Table 8.4 \" title=\"Table 8.4 \">8.4</a> also shows  the number of bits by which each received 3-tuple differs from each original codeword.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  Maximum-Likelihood Decoding\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">Maximum-Likelihood Decoding</span></h3><a href=\"section-error-detecting-correcting-codes.ipynb#algcodes-subsection-max-likelihood\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1208\">The coding scheme presented in Example <a href=\"section-error-detecting-correcting-codes.ipynb#example-algcodes-nearest\" class=\"xref\" alt=\"Example 8.5 \" title=\"Example 8.5 \">8.5</a> is not a complete solution to the problem because it does not account for the possibility of multiple errors. For example, either a (000) or a (111) could be sent and a (001) received. We have no means of deciding from the received word whether there was a single error in the third bit or two errors, one in the first bit and one in the second.  No matter what coding  scheme is used, an incorrect message could be received. We could transmit a (000), have errors in all three bits, and receive the codeword (111). It is important to make explicit assumptions about the likelihood and distribution of transmission errors so that, in a particular application, it will be known whether a given error detection scheme is appropriate. We will assume that transmission errors are rare, and, that when they do occur, they occur independently in each bit; that is, if $p$ is the probability of an error in one bit and $q$ is the probability of an error in a different bit, then the probability of errors occurring in both of these bits at the same time is $pq\\text{.}$ We will also assume that a received $n$-tuple is decoded into a codeword that is closest to it; that is, we assume that the receiver uses <dfn class=\"terminology\">maximum-likelihood decoding</dfn>.<span class=\"footnote\"><a knowl=\"\" class=\"id-ref\" refid=\"hk-fn-3\" id=\"fn-3\"><sup> 3 </sup></a></span><span id=\"hk-fn-3\" class=\"hidden-content tex2jax_ignore\"><span class=\"footnote\">This section requires a knowledge of probability, but can be skipped without loss of continuity.</span></span></p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"figure-channel\"><img src=\"images/algcodes-binary-channel.svg\" width=\"40%\" alt=\"\" /><figcaption><span class=\"type\">Figure</span><span class=\"codenumber\">8.6</span>Binary symmetric channel</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1209\">A <dfn class=\"terminology\">binary symmetric channel</dfn> is a model that consists of a transmitter capable of sending a binary  signal, either a 0 or a 1, together with a receiver. Let $p$ be the probability that the signal is correctly received. Then $q = 1 - p$ is the probability of an incorrect reception. If a 1 is sent, then the probability that a 1 is received is $p$ and the probability that a 0 is received is $q$ (Figure <a href=\"section-error-detecting-correcting-codes.ipynb#figure-channel\" class=\"xref\" alt=\"Figure 8.6 \" title=\"Figure 8.6 \">8.6</a>). The probability that no errors occur during the transmission of a binary codeword of length $n$ is $p^{n}\\text{.}$ For example, if $p=0.999$ and a message consisting of 10,000 bits is sent, then the probability of a perfect transmission is</p><div class=\"displaymath\">\n\\begin{equation*}\n(0.999)^{10,000} \\approx 0.00005.\n\\end{equation*}\n</div></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"theorem-31\"><h6 class=\"heading\"><span class=\"type\">Theorem</span><span class=\"codenumber\">8.7</span></h6><p id=\"p-1210\">If a binary $n$-tuple $(x_{1}, \\ldots, x_{n})$ is transmitted across a binary symmetric channel with probability $p$ that no error will occur in each coordinate, then the probability that there are errors in exactly $k$ coordinates is</p><div class=\"displaymath\">\n\\begin{equation*}\n\\binom{n}{k} q^kp^{n - k}.\n\\end{equation*}\n</div></article><article class=\"proof\" id=\"proof-45\"><h6 class=\"heading\"><span class=\"type\">Proof</span></h6><p id=\"p-1211\">Fix $k$ different coordinates. We first compute the probability that an error has occurred in this fixed set of coordinates. The probability of an error occurring in a particular one of these $k$ coordinates is $q\\text{;}$ the probability that an error will not occur in any of the remaining $n-k$ coordinates is $p\\text{.}$ The probability of each of these $n$ independent events is $q^{k}p^{n-k}\\text{.}$ The number of possible error patterns with exactly $k$ errors occurring is equal to</p><div class=\"displaymath\">\n\\begin{equation*}\n\\binom{n}{k}  = \\frac{n!}{k!(n - k)!},\n\\end{equation*}\n</div><p>the number of combinations of $n$ things taken $k$ at a time. Each of these error patterns has probability $q^{k}p^{n-k}$ of occurring; hence, the probability of all of these error patterns is</p><div class=\"displaymath\">\n\\begin{equation*}\n\\binom{n}{k}  q^{k}p^{n - k}. \n\\end{equation*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-probability\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.8</span></h6><p id=\"p-1212\">Suppose that $p = 0.995$ and a 500-bit message is sent. The probability that the message was sent error-free is</p><div class=\"displaymath\">\n\\begin{equation*}\np^{n} = (0.995)^{500} \\approx 0.082.\n\\end{equation*}\n</div><p>The probability of exactly one error occurring is</p><div class=\"displaymath\">\n\\begin{equation*}\n\\binom{n}{1}  qp^{n - 1}= 500(0.005)(0.995)^{499} \\approx 0.204.\n\\end{equation*}\n</div><p>The probability of exactly two errors is</p><div class=\"displaymath\">\n\\begin{equation*}\n\\binom{n}{2} q^{2}p^{n - 2}= \\frac{500 \\cdot 499}{2}(0.005)^{2}(0.995)^{498} \\approx 0.257.\n\\end{equation*}\n</div><p>The probability of more than two errors is approximately</p><div class=\"displaymath\">\n\\begin{equation*}\n1 - 0.082 - 0.204 - 0.257 = 0.457.\n\\end{equation*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  Block Codes\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">Block Codes</span></h3><a href=\"section-error-detecting-correcting-codes.ipynb#algcodes-subsection-block-codes\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1213\">If we are to develop efficient error-detecting and error-correcting codes, we will need more sophisticated mathematical tools.  Group theory  will allow faster methods of encoding and decoding messages. A code is an $(n, m)$-<dfn class=\"terminology\">block code</dfn> if the information that is to be coded can be divided into blocks of $m$ binary digits, each of which can be encoded into $n$ binary digits. More specifically, an $(n, m)$-block code consists of an <dfn class=\"terminology\">encoding function</dfn></p><div class=\"displaymath\">\n\\begin{equation*}\nE:{\\mathbb Z}^{m}_{2} \\rightarrow {\\mathbb Z}^{n}_{2}\n\\end{equation*}\n</div><p>and a <dfn class=\"terminology\">decoding function</dfn></p><div class=\"displaymath\">\n\\begin{equation*}\nD:{\\mathbb Z}^{n}_{2} \\rightarrow {\\mathbb Z}^{m}_{2}.\n\\end{equation*}\n</div><p>A <dfn class=\"terminology\">codeword</dfn> is any element in the image of $E\\text{.}$ We also require that $E$ be one-to-one so that two information blocks will not be encoded into the same codeword. If our code is to be error-correcting, then $D$ must be onto.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-block-code\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.9</span></h6><p id=\"p-1214\">The even-parity coding system developed to detect single errors in <abbr class=\"acronym\">ASCII</abbr> characters is an $(8,7)$-block code. The encoding function is</p><div class=\"displaymath\">\n\\begin{equation*}\nE(x_7, x_6, \\ldots, x_1) = (x_8, x_7,  \\ldots, x_1),\n\\end{equation*}\n</div><p>where $x_8 = x_7 + x_6 + \\cdots + x_1$ with addition in ${\\mathbb Z}_2\\text{.}$</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1215\">Let ${\\mathbf x} = (x_1, \\ldots, x_n)$ and ${\\mathbf y} = (y_1, \\ldots, y_n)$ be binary $n$-tuples. The <dfn class=\"terminology\">Hamming distance</dfn> or <dfn class=\"terminology\">distance</dfn>, $d({\\mathbf x}, {\\mathbf y})\\text{,}$ between ${\\mathbf x}$ and ${\\mathbf y}$ is the number of bits in which ${\\mathbf x}$ and ${\\mathbf y}$ differ. The distance between two codewords is the minimum number of transmission errors required to change one codeword into the other. The <dfn class=\"terminology\">minimum distance</dfn> for a code, $d_{\\min}\\text{,}$ is the minimum of all distances $d({\\mathbf x}, {\\mathbf y})\\text{,}$ where ${\\mathbf x}$ and ${\\mathbf y}$ are distinct codewords. The <dfn class=\"terminology\">weight</dfn>, $w({\\mathbf x})\\text{,}$ of a binary codeword ${\\mathbf x}$ is the number of 1s in ${\\mathbf x}\\text{.}$ Clearly, $w({\\mathbf x}) = d({\\mathbf x}, {\\mathbf 0})\\text{,}$ where ${\\mathbf 0} = (00 \\cdots 0)\\text{.}$   </p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-min-distance\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.10</span></h6><p id=\"p-1216\">Let ${\\mathbf x} = (10101)\\text{,}$ ${\\mathbf y} = (11010)\\text{,}$ and ${\\mathbf z} = (00011)$ be all of the codewords in some code $C\\text{.}$ Then we have the following Hamming distances:</p><div class=\"displaymath\">\n\\begin{equation*}\nd({\\mathbf x},{\\mathbf y}) = 4, \\qquad d({\\mathbf x},{\\mathbf z}) = 3, \\qquad d({\\mathbf y},{\\mathbf z}) = 3.\n\\end{equation*}\n</div><p>The minimum distance  for this code is 3. We also have the following weights:</p><div class=\"displaymath\">\n\\begin{equation*}\nw({\\mathbf x}) = 3, \\qquad w({\\mathbf y}) = 3, \\qquad w({\\mathbf z}) = 2.\n\\end{equation*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1217\">The following proposition lists some basic properties about the weight of a codeword and the distance between two codewords. The proof is left as an exercise.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"proposition-20\"><h6 class=\"heading\"><span class=\"type\">Proposition</span><span class=\"codenumber\">8.11</span></h6><p id=\"p-1218\">Let ${\\mathbf x}\\text{,}$ ${\\mathbf y}\\text{,}$ and ${\\mathbf z}$ be binary $n$-tuples. Then </p><ol class=\"decimal\"><li id=\"li-299\"><p id=\"p-1219\">$w({\\mathbf x}) = d( {\\mathbf x}, {\\mathbf 0})\\text{;}$</p></li><li id=\"li-300\"><p id=\"p-1220\">$d( {\\mathbf x}, {\\mathbf y}) \\geq 0\\text{;}$</p></li><li id=\"li-301\"><p id=\"p-1221\">$d( {\\mathbf x}, {\\mathbf y}) = 0$ exactly when ${\\mathbf x} = {\\mathbf y}\\text{;}$</p></li><li id=\"li-302\"><p id=\"p-1222\">$d( {\\mathbf x}, {\\mathbf y})= d( {\\mathbf y}, {\\mathbf x})\\text{;}$</p></li><li id=\"li-303\"><p id=\"p-1223\">$d( {\\mathbf x}, {\\mathbf y}) \\leq d( {\\mathbf x}, {\\mathbf z}) + d( {\\mathbf z}, {\\mathbf y})\\text{.}$</p></li></ol></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1224\">The weights in a particular code are usually much easier to compute than the Hamming distances between all codewords in the code. If a code is set up carefully, we can use this fact to our advantage.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1225\">Suppose that ${\\mathbf x} = (1101)$ and ${\\mathbf y} = (1100)$ are codewords in some code. If we transmit (1101) and an error occurs in the rightmost bit, then (1100) will be received. Since (1100) is a codeword, the decoder will decode (1100) as the transmitted message. This code is clearly not very appropriate for error detection. The problem is that $d({\\mathbf x}, {\\mathbf y}) = 1\\text{.}$ If ${\\mathbf x} = (1100)$ and ${\\mathbf y} = (1010)$ are codewords, then $d({\\mathbf x}, {\\mathbf y}) = 2\\text{.}$ If ${\\mathbf x}$ is transmitted and a single error occurs, then ${\\mathbf y}$ can never be received. Table <a href=\"section-error-detecting-correcting-codes.ipynb#table-4-bit-words\" class=\"xref\" alt=\"Table 8.12 \" title=\"Table 8.12 \">8.12</a> gives the distances between all 4-bit codewords in which the first three bits carry information and the fourth is an even parity check bit. We can see that the minimum distance here is 2; hence, the code is suitable as a single error-detecting code.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"table-4-bit-words\"><table><tr><td class=\"c m b2 r2 l2 t2 lines\" /><td class=\"c m b2 r2 l0 t2 lines\">0000</td><td class=\"c m b2 r2 l0 t2 lines\">0011</td><td class=\"c m b2 r2 l0 t2 lines\">0101</td><td class=\"c m b2 r2 l0 t2 lines\">0110</td><td class=\"c m b2 r2 l0 t2 lines\">1001</td><td class=\"c m b2 r2 l0 t2 lines\">1010</td><td class=\"c m b2 r2 l0 t2 lines\">1100</td><td class=\"c m b2 r2 l0 t2 lines\">1111</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">0000</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">0011</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">0101</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">0110</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">1001</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">1010</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">1100</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">2</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">2</td></tr><tr><td class=\"c m b2 r2 l2 t0 lines\">1111</td><td class=\"c m b2 r2 l0 t0 lines\">4</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">2</td><td class=\"c m b2 r2 l0 t0 lines\">0</td></tr></table><figcaption><span class=\"type\">Table</span><span class=\"codenumber\">8.12</span>Distances between 4-bit codewords</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1226\">To determine exactly what the error-detecting and error-correcting capabilities for a code are, we need to analyze the minimum distance for the code. Let ${\\mathbf x}$ and ${\\mathbf y}$ be codewords. If $d({\\mathbf x}, {\\mathbf y}) = 1$ and an error occurs where ${\\mathbf x}$ and ${\\mathbf y}$ differ, then ${\\mathbf x}$ is changed to ${\\mathbf y}\\text{.}$ The received codeword is ${\\mathbf y}$ and no error message is given. Now suppose $d({\\mathbf x}, {\\mathbf y}) = 2\\text{.}$ Then a single error cannot change ${\\mathbf x}$ to ${\\mathbf y}\\text{.}$ Therefore, if $d_{\\min} = 2\\text{,}$ we have the ability to detect single errors. However, suppose that $d({\\mathbf x}, {\\mathbf y}) = 2\\text{,}$ ${\\mathbf y}$ is sent, and a noncodeword ${\\mathbf z}$ is received such that</p><div class=\"displaymath\">\n\\begin{equation*}\nd({\\mathbf x}, {\\mathbf z}) = d({\\mathbf y}, {\\mathbf z}) = 1.\n\\end{equation*}\n</div><p>Then the decoder cannot decide between ${\\mathbf x}$ and ${\\mathbf y}\\text{.}$ Even though we are aware that an error has occurred, we do not know what the error is.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1227\">Suppose $d_{\\min} \\geq 3\\text{.}$ Then the maximum-likelihood decoding scheme corrects all single errors. Starting with a codeword ${\\mathbf x}\\text{,}$ an error in the transmission of a single bit gives ${\\mathbf y}$ with $d({\\mathbf x}, {\\mathbf y}) = 1\\text{,}$ but $d({\\mathbf z}, {\\mathbf y}) \\geq 2$ for any other codeword ${\\mathbf z} \\neq {\\mathbf x}\\text{.}$ If we do not require the correction of errors, then we can detect multiple errors when a code has a minimum distance that is greater than or equal to 3.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"theorem-min-distance\"><h6 class=\"heading\"><span class=\"type\">Theorem</span><span class=\"codenumber\">8.13</span></h6><p id=\"p-1228\">Let $C$ be a code with $d_{\\min} = 2n + 1\\text{.}$ Then $C$ can correct any $n$ or fewer errors.  Furthermore, any $2n$ or fewer errors can be detected in $C\\text{.}$</p></article><article class=\"proof\" id=\"proof-46\"><h6 class=\"heading\"><span class=\"type\">Proof</span></h6><p id=\"p-1229\">Suppose that a codeword ${\\mathbf x}$ is sent and the word ${\\mathbf y}$ is received with at most $n$ errors. Then $d( {\\mathbf x}, {\\mathbf y}) \\leq n\\text{.}$ If ${\\mathbf z}$ is any codeword other than ${\\mathbf x}\\text{,}$ then</p><div class=\"displaymath\">\n\\begin{equation*}\n2n+1 \\leq d( {\\mathbf x}, {\\mathbf z}) \\leq d( {\\mathbf x}, {\\mathbf y}) + d( {\\mathbf y}, {\\mathbf z}) \\leq n + d( {\\mathbf y}, {\\mathbf z}).\n\\end{equation*}\n</div><p>Hence, $d({\\mathbf y}, {\\mathbf z} ) \\geq n+1$ and ${\\mathbf y}$ will be correctly decoded as ${\\mathbf x}\\text{.}$ Now suppose that ${\\mathbf x}$ is transmitted and ${\\mathbf y}$ is received and that at least one error  has occurred, but not more than $2n$ errors. Then $1 \\leq d( {\\mathbf x}, {\\mathbf y} ) \\leq 2n\\text{.}$  Since the minimum distance between codewords is $2n +1\\text{,}$ ${\\mathbf y}$ cannot be a codeword.  Consequently, the code can detect between 1 and $2n$ errors.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-algcodes-single-correct\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">8.14</span></h6><p id=\"p-1230\">In Table <a href=\"section-error-detecting-correcting-codes.ipynb#table-hamming-distance\" class=\"xref\" alt=\"Table 8.15 \" title=\"Table 8.15 \">8.15</a>, the codewords ${\\mathbf c}_1 = (00000)\\text{,}$ ${\\mathbf c}_2 = (00111)\\text{,}$ ${\\mathbf c}_3 = (11100)\\text{,}$ and ${\\mathbf c}_4 = (11011)$ determine a single error-correcting code.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"table-hamming-distance\"><table><tr><td class=\"c m b2 r2 l2 t2 lines\" /><td class=\"c m b2 r2 l0 t2 lines\">00000</td><td class=\"c m b2 r2 l0 t2 lines\">00111</td><td class=\"c m b2 r2 l0 t2 lines\">11100</td><td class=\"c m b2 r2 l0 t2 lines\">11011</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">00000</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">3</td><td class=\"c m b0 r2 l0 t0 lines\">3</td><td class=\"c m b0 r2 l0 t0 lines\">4</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">00111</td><td class=\"c m b0 r2 l0 t0 lines\">3</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">3</td></tr><tr><td class=\"c m b0 r2 l2 t0 lines\">11100</td><td class=\"c m b0 r2 l0 t0 lines\">3</td><td class=\"c m b0 r2 l0 t0 lines\">4</td><td class=\"c m b0 r2 l0 t0 lines\">0</td><td class=\"c m b0 r2 l0 t0 lines\">3</td></tr><tr><td class=\"c m b2 r2 l2 t0 lines\">11011</td><td class=\"c m b2 r2 l0 t0 lines\">4</td><td class=\"c m b2 r2 l0 t0 lines\">3</td><td class=\"c m b2 r2 l0 t0 lines\">3</td><td class=\"c m b2 r2 l0 t0 lines\">0</td></tr></table><figcaption><span class=\"type\">Table</span><span class=\"codenumber\">8.15</span>Hamming distances for an error-correcting code</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  Historical Note\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">Historical Note</span></h3><a href=\"section-error-detecting-correcting-codes.ipynb#algcodes-subsection-historical-note\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1231\">Modern coding theory began in 1948 with C. Shannon's paper, “A Mathematical Theory of Information” [7]. This paper offered an example of an algebraic code, and Shannon's Theorem proclaimed exactly how good codes could be expected to be. Richard Hamming began working with linear codes at Bell Labs in the late 1940s and early 1950s after becoming frustrated because the programs that he was running could not recover from simple errors generated by noise. Coding theory has grown tremendously in the past several decades. <em class=\"emphasis\">The Theory of Error-Correcting Codes</em>, by MacWilliams and Sloane [5], published in 1977, already contained over 1500 references. Linear codes (Reed-Muller $(32, 6)$-block codes) were used on NASA's Mariner space probes.  More recent space probes such as Voyager have used what are called convolution codes.  Currently, very active research is being done with Goppa codes, which are heavily dependent on algebraic geometry.</p></div>"]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "sagemath"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.8"}, "name": "section-error-detecting-correcting-codes.ipynb"}
}
{
"cells": [
{"cell_type":    "code", "execution_count":null, "metadata":{}, "source":["%%html\n<link href=\"http://mathbook.pugetsound.edu/beta/mathbook-content.css\" rel=\"stylesheet\" type=\"text/css\" />\n<link href=\"https://aimath.org/mathbook/mathbook-add-on.css\" rel=\"stylesheet\" type=\"text/css\" />\n<style>.subtitle {font-size:medium; display:block}</style>\n<link href=\"https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic\" rel=\"stylesheet\" type=\"text/css\" />\n<link href=\"https://fonts.googleapis.com/css?family=Inconsolata:400,700&subset=latin,latin-ext\" rel=\"stylesheet\" type=\"text/css\" /><!-- Hide this cell. -->\n<script>\nvar cell = $(\".container .cell\").eq(0), ia = cell.find(\".input_area\")\nif (cell.find(\".toggle-button\").length == 0) {\nia.after(\n    $('<button class=\"toggle-button\">Toggle hidden code</button>').click(\n        function (){ ia.toggle() }\n        )\n    )\nia.hide()\n}\n</script>\n"], "outputs":[]},
{"cell_type":"markdown", "metadata":{}, "source":["**Important:** to view this notebook properly you will need to execute the cell above, which assumes you have an Internet connection.  It should already be selected, or place your cursor anywhere above to select.  Then press the \"Run\" button in the menu bar above (the right-pointing arrowhead), or press Shift-Enter on your keyboard."]},
{"cell_type":"markdown", "metadata":{}, "source":["$\\newcommand{\\identity}{\\mathrm{id}}\n\\newcommand{\\notdivide}{\\nmid}\n\\newcommand{\\notsubset}{\\not\\subset}\n\\newcommand{\\lcm}{\\operatorname{lcm}}\n\\newcommand{\\gf}{\\operatorname{GF}}\n\\newcommand{\\inn}{\\operatorname{Inn}}\n\\newcommand{\\aut}{\\operatorname{Aut}}\n\\newcommand{\\Hom}{\\operatorname{Hom}}\n\\newcommand{\\cis}{\\operatorname{cis}}\n\\newcommand{\\chr}{\\operatorname{char}}\n\\newcommand{\\Null}{\\operatorname{Null}}\n\\newcommand{\\lt}{<}\n\\newcommand{\\gt}{>}\n\\newcommand{\\amp}{&}\n$"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h2 class=\"heading hide-type\" alt=\"Section 12.1 Matrix Groups\"><span class=\"type\">Section</span><span class=\"codenumber\">12.1</span><span class=\"title\">Matrix Groups</span></h2><a href=\"section-matrix-groups.ipynb\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  Some Facts from Linear Algebra\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">Some Facts from Linear Algebra</span></h3><a href=\"section-matrix-groups.ipynb#matrix-subsection-linear-algebra\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1811\">Before we study matrix groups, we must recall some basic facts from linear algebra.  One of the most fundamental ideas of linear algebra is that of a linear transformation. A <dfn class=\"terminology\">linear transformation</dfn> or <dfn class=\"terminology\">linear map</dfn> $T : {\\mathbb R}^n \\rightarrow {\\mathbb R}^m$ is a map that preserves vector addition and scalar multiplication; that is, for vectors ${\\mathbf x}$ and ${\\mathbf y}$ in ${\\mathbb R}^n$ and a scalar $\\alpha \\in {\\mathbb R}\\text{,}$</p><div class=\"displaymath\">\n\\begin{align*}\nT({\\mathbf x}+{\\mathbf y}) & = T({\\mathbf x}) + T({\\mathbf y})\\\\\nT(\\alpha {\\mathbf y}) & = \\alpha T({\\mathbf y}).\n\\end{align*}\n</div><p>An $m \\times n$ matrix with entries in ${\\mathbb R}$ represents a linear transformation from ${\\mathbb R}^n$ to ${\\mathbb R}^m\\text{.}$ If we write vectors ${\\mathbf x} = (x_1, \\ldots, x_n)^{\\rm t}$ and ${\\mathbf y} = (y_1, \\ldots, y_n)^{\\rm t}$ in ${\\mathbb R}^n$ as column matrices, then an $m \\times n$ matrix</p><div class=\"displaymath\">\n\\begin{equation*}\nA\n=\n\\begin{pmatrix}\na_{11} & a_{12} & \\cdots & a_{1n} \\\\\na_{21} & a_{22} & \\cdots & a_{2n} \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\na_{m1} & a_{m2} & \\cdots & a_{mn}\n\\end{pmatrix}\n\\end{equation*}\n</div><p>maps the vectors to ${\\mathbb R}^m$ linearly by matrix multiplication.  Observe that if $\\alpha$ is a real number,</p><div class=\"displaymath\">\n\\begin{equation*}\nA({\\mathbf x} + {\\mathbf y} ) \n= \nA {\\mathbf x }+ A {\\mathbf y} \n\\qquad \\text{and} \\qquad\n\\alpha A {\\mathbf x} \n= \nA ( \\alpha {\\mathbf x}),\n\\end{equation*}\n</div><p>where</p><div class=\"displaymath\">\n\\begin{equation*}\n{\\mathbf x}\n=\n\\begin{pmatrix}\nx_1 \\\\\nx_2 \\\\\n\\vdots \\\\\nx_n\n\\end{pmatrix}.\n\\end{equation*}\n</div><p>We will often abbreviate the matrix $A$ by writing $(a_{ij})\\text{.}$ </p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1812\">Conversely, if $T : {\\mathbb R}^n \\rightarrow {\\mathbb R}^m$ is a linear map, we can associate a matrix $A$ with $T$ by considering what $T$ does to the vectors</p><div class=\"displaymath\">\n\\begin{align*}\n{\\mathbf e}_1 & = (1, 0, \\ldots, 0)^{\\rm t}\\\\\n{\\mathbf e}_2 & = (0, 1, \\ldots, 0)^{\\rm t}\\\\\n&  \\vdots & \\\\\n{\\mathbf e}_n & = (0, 0, \\ldots, 1)^{\\rm t}.\n\\end{align*}\n</div><p>We can write any vector ${\\mathbf x} = (x_1, \\ldots, x_n)^{\\rm t}$ as</p><div class=\"displaymath\">\n\\begin{equation*}\nx_1 {\\mathbf e}_1 + x_2 {\\mathbf e}_2 + \\cdots + x_n {\\mathbf e}_n.\n\\end{equation*}\n</div><p>Consequently, if</p><div class=\"displaymath\">\n\\begin{align*}\nT({\\mathbf e}_1) & = (a_{11}, a_{21}, \\ldots, a_{m1})^{\\rm t},\\\\\nT({\\mathbf e}_2) & = (a_{12}, a_{22}, \\ldots, a_{m2})^{\\rm t},\\\\\n&  \\vdots & \\\\\nT({\\mathbf e}_n) & = (a_{1n}, a_{2n}, \\ldots, a_{mn})^{\\rm t},\n\\end{align*}\n</div><p>then</p><div class=\"displaymath\">\n\\begin{align*}\nT({\\mathbf x} ) & = T(x_1 {\\mathbf e}_1 + x_2 {\\mathbf e}_2 + \\cdots + x_n {\\mathbf e}_n)\\\\\n& = x_1 T({\\mathbf e}_1) + x_2 T({\\mathbf e}_2) + \\cdots + x_n T({\\mathbf e}_n)\\\\\n& = \\left( \\sum_{k=1}^{n} a_{1k} x_k, \\ldots,  \\sum_{k=1}^{n} a_{mk} x_k \\right)^{\\rm t}\\\\\n& = A {\\mathbf x}.\n\\end{align*}\n</div></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-linear-transform\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.1</span></h6><p id=\"p-1813\">If we let $T : {\\mathbb R}^2 \\rightarrow {\\mathbb R}^2$ be the map given by</p><div class=\"displaymath\">\n\\begin{equation*}\nT(x_1, x_2) = (2 x_1 + 5 x_2, - 4 x_1 + 3 x_2),\n\\end{equation*}\n</div><p>the axioms that $T$ must satisfy to be a linear transformation are easily verified. The column vectors $T {\\mathbf e}_1 = (2, -4)^{\\rm t}$ and $T {\\mathbf e}_2 = (5,3)^{\\rm t}$  tell us that $T$ is given by the matrix</p><div class=\"displaymath\">\n\\begin{equation*}\nA =\n\\begin{pmatrix}\n2 & 5 \\\\\n-4 & 3\n\\end{pmatrix}.\n\\end{equation*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1814\">Since we are interested in groups of matrices, we need to know which matrices have multiplicative inverses. Recall that an $n \\times n$ matrix $A$ is <dfn class=\"terminology\">invertible</dfn> exactly when there exists another matrix $A^{-1}$ such that $A A^{-1} = A^{-1} A = I\\text{,}$ where</p><div class=\"displaymath\">\n\\begin{equation*}\nI =\n\\begin{pmatrix}\n1 & 0 & \\cdots & 0 \\\\\n0 & 1 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & 1\n\\end{pmatrix}\n\\end{equation*}\n</div><p>is the $n \\times n$ identity matrix. From linear algebra we know that $A$ is invertible if and only if the determinant of $A$ is nonzero. Sometimes an invertible matrix is said to be <dfn class=\"terminology\">nonsingular</dfn>.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"inverse_matrix\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.2</span></h6><p id=\"p-1815\">If $A$ is the matrix</p><div class=\"displaymath\">\n\\begin{equation*}\n\\begin{pmatrix}\n2 & 1 \\\\\n5 & 3\n\\end{pmatrix},\n\\end{equation*}\n</div><p>then the inverse of $A$ is</p><div class=\"displaymath\">\n\\begin{equation*}\nA^{-1} =\n\\begin{pmatrix}\n3 & -1 \\\\\n-5 & 2\n\\end{pmatrix}.\n\\end{equation*}\n</div><p>We are guaranteed  that $A^{-1}$ exists, since $\\det(A) = 2 \\cdot 3 - 5 \\cdot 1 = 1$ is nonzero.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1816\">Some other facts about determinants will also prove useful in the course of this chapter.   Let $A$ and $B$ be $n \\times n$ matrices. From linear algebra we have the following properties of determinants. </p><ul class=\"disc\"><li id=\"li-418\"><p id=\"p-1817\">The determinant is a homomorphism into the multiplicative group of real numbers; that is, $\\det( A B) = (\\det A )(\\det B)\\text{.}$</p></li><li id=\"li-419\"><p id=\"p-1818\">If $A$ is an invertible matrix, then $\\det(A^{-1}) = 1 / \\det A\\text{.}$</p></li><li id=\"li-420\"><p id=\"p-1819\">If we define the transpose  of a matrix $A = (a_{ij})$ to be $A^{\\rm t} = (a_{ji})\\text{,}$ then $\\det(A^{\\rm t}) = \\det A\\text{.}$</p></li><li id=\"li-421\"><p id=\"p-1820\">Let $T$ be the linear transformation associated with an $n \\times n$ matrix $A\\text{.}$ Then $T$ multiplies volumes by a factor of $|\\det A|\\text{.}$ In the case of ${\\mathbb R}^2\\text{,}$ this means that $T$ multiplies areas by $|\\det A|\\text{.}$</p></li></ul></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1821\">Linear maps, matrices, and determinants are covered in any elementary linear algebra text; however, if you have not had a course in linear algebra, it is a straightforward process to verify these properties directly for $2 \\times 2$ matrices, the case with which we are most concerned.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  The General and Special Linear Groups\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">The General and Special Linear Groups</span></h3><a href=\"section-matrix-groups.ipynb#matrix-subsection-general-linear-group\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1822\">The set of all $n \\times n$  invertible matrices forms a group called the <dfn class=\"terminology\">general linear group</dfn>.  We will denote this group by $GL_n({\\mathbb R})\\text{.}$  The general linear group has several important subgroups. The multiplicative properties of the determinant imply that the set of matrices with determinant one is a subgroup of the general linear group.  Stated another way, suppose that $\\det(A) =1$ and $\\det(B) = 1\\text{.}$ Then $\\det(AB) = \\det(A) \\det (B) = 1$ and $\\det(A^{-1}) = 1 / \\det A = 1\\text{.}$ This subgroup is called the <dfn class=\"terminology\">special linear group</dfn> and is denoted by $SL_n({\\mathbb R})\\text{.}$</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-determinant\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.3</span></h6><p id=\"p-1823\">Given a $2 \\times 2$ matrix</p><div class=\"displaymath\">\n\\begin{equation*}\nA =\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix},\n\\end{equation*}\n</div><p>the determinant of $A$ is $ad-bc\\text{.}$ The group $GL_2({\\mathbb R})$ consists of those matrices in which $ad-bc \\neq 0\\text{.}$ The inverse of $A$ is</p><div class=\"displaymath\">\n\\begin{equation*}\nA^{-1} =\n\\frac{1}{ad-bc}\n\\begin{pmatrix}\nd & -b \\\\\n-c & a\n\\end{pmatrix}.\n\\end{equation*}\n</div><p>If $A$ is in $SL_2({\\mathbb R})\\text{,}$ then</p><div class=\"displaymath\">\n\\begin{equation*}\nA^{-1} =\n\\begin{pmatrix}\nd & -b \\\\\n-c & a\n\\end{pmatrix}.\n\\end{equation*}\n</div><p>Geometrically, $SL_2({\\mathbb R})$ is the group that preserves the areas of parallelograms.  Let</p><div class=\"displaymath\">\n\\begin{equation*}\nA =\n\\begin{pmatrix}\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix}\n\\end{equation*}\n</div><p>be in $SL_2({\\mathbb R})\\text{.}$ In Figure <a href=\"section-matrix-groups.ipynb#figure-sl2\" class=\"xref\" alt=\"Figure 12.4 \" title=\"Figure 12.4 \">12.4</a>, the unit square corresponding to the vectors ${\\mathbf x} = (1,0)^{\\rm t}$ and ${\\mathbf y} =  (0,1)^{\\rm t}$ is taken  by $A$ to the parallelogram with sides $(1,0)^{\\rm t}$ and $(1, 1)^{\\rm t}\\text{;}$ that is, $A {\\mathbf x} = (1,0)^{\\rm t}$ and $A {\\mathbf y} = (1, 1)^{\\rm t}\\text{.}$ Notice that these two parallelograms have the same area.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"figure-sl2\"><img src=\"images/matrix-sl2r.svg\" width=\"100%\" alt=\"\" /><figcaption><span class=\"type\">Figure</span><span class=\"codenumber\">12.4</span>$SL_2(\\mathbb R)$ acting on the unit square</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><h3 class=\"heading hide-type\" alt=\"Subsection  The Orthogonal Group $O(n)$\"><span class=\"type\">Subsection</span><span class=\"codenumber\" /><span class=\"title\">The Orthogonal Group $O(n)$</span></h3><a href=\"section-matrix-groups.ipynb#matrix-subsection-orthogonal-group\" class=\"permalink\">¶</a></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1824\">Another subgroup of $GL_n({\\mathbb R})$ is the orthogonal group. A matrix $A$ is <dfn class=\"terminology\">orthogonal</dfn> if $A^{-1} = A^{\\rm t}\\text{.}$ The <dfn class=\"terminology\">orthogonal group</dfn> consists of the set of all orthogonal matrices. We write $O(n)$ for the $n \\times n$ orthogonal group.  We leave as an exercise the proof that $O(n)$ is a subgroup of $GL_n( {\\mathbb R})\\text{.}$</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"orthogonal\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.5</span></h6><p id=\"p-1825\">The following matrices are orthogonal:</p><div class=\"displaymath\">\n\\begin{equation*}\n\\begin{pmatrix}\n3/5 & -4/5 \\\\\n4/5 & 3/5\n\\end{pmatrix}, \n\\quad\n\\begin{pmatrix}\n1/2 & -\\sqrt{3}/2 \\\\\n\\sqrt{3}/2 & 1/2\n\\end{pmatrix}, \n\\quad\n\\begin{pmatrix}\n-1/\\sqrt{2} & 0 & 1/ \\sqrt{2} \\\\\n1/\\sqrt{6} & -2/\\sqrt{6} & 1/\\sqrt{6} \\\\\n1/ \\sqrt{3} & 1/ \\sqrt{3} & 1/ \\sqrt{3} \n\\end{pmatrix}.\n\\end{equation*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1826\">There is a more geometric way of viewing the group $O(n)\\text{.}$ The orthogonal matrices are exactly those matrices that preserve the length of vectors. We can define the length of a vector using the <dfn class=\"terminology\">Euclidean inner product</dfn>, or <dfn class=\"terminology\">dot product</dfn>, of two vectors. The Euclidean inner product of two vectors ${\\mathbf x}=(x_1, \\ldots, x_n)^{\\rm t}$ and ${\\mathbf y}=(y_1, \\ldots, y_n)^{\\rm t}$ is</p><div class=\"displaymath\">\n\\begin{equation*}\n\\langle  {\\mathbf x}, {\\mathbf y} \\rangle\n=\n{\\mathbf x}^{\\rm t}  {\\mathbf y}\n=\n(x_1, x_2, \\ldots, x_n)\n\\begin{pmatrix}\ny_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n\n\\end{pmatrix}\n=\nx_1 y_1 + \\cdots + x_n y_n.\n\\end{equation*}\n</div><p>We define the length of a vector ${\\mathbf x}=(x_1, \\ldots, x_n)^{\\rm t}$ to be </p><div class=\"displaymath\">\n\\begin{equation*}\n\\| {\\mathbf x} \\| = \\sqrt{\\langle  {\\mathbf x}, {\\mathbf x} \\rangle}  = \\sqrt{x_1^2 + \\cdots + x_n^2}.\n\\end{equation*}\n</div><p>Associated with the notion of the length of a vector is the idea of the distance between two vectors. We define the <dfn class=\"terminology\">distance</dfn> between two vectors ${\\mathbf x}$ and ${\\mathbf y}$ to be $\\| {\\mathbf x}-{\\mathbf y} \\|\\text{.}$ We leave as an exercise the proof of the following proposition about the properties of Euclidean inner products.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"proposition-26\"><h6 class=\"heading\"><span class=\"type\">Proposition</span><span class=\"codenumber\">12.6</span></h6><p id=\"p-1827\">Let ${\\mathbf x}\\text{,}$ ${\\mathbf y}\\text{,}$ and ${\\mathbf w}$ be vectors in ${\\mathbb R}^n$ and $\\alpha \\in {\\mathbb R}\\text{.}$ Then </p><ol class=\"decimal\"><li id=\"li-422\"><p id=\"p-1828\">$\\langle {\\mathbf x}, {\\mathbf y} \\rangle = \\langle {\\mathbf y}, {\\mathbf x} \\rangle\\text{.}$</p></li><li id=\"li-423\"><p id=\"p-1829\">$\\langle {\\mathbf x}, {\\mathbf y} + {\\mathbf w} \\rangle = \\langle {\\mathbf x}, {\\mathbf y} \\rangle + \\langle {\\mathbf x}, {\\mathbf w} \\rangle\\text{.}$</p></li><li id=\"li-424\"><p id=\"p-1830\">$\\langle \\alpha {\\mathbf x}, {\\mathbf y} \\rangle = \\langle {\\mathbf x}, \\alpha {\\mathbf y} \\rangle = \\alpha \\langle  {\\mathbf x}, {\\mathbf y} \\rangle\\text{.}$</p></li><li id=\"li-425\"><p id=\"p-1831\">$\\langle {\\mathbf x}, {\\mathbf x} \\rangle \\geq 0$ with equality exactly when ${\\mathbf x} = 0\\text{.}$</p></li><li id=\"li-426\"><p id=\"p-1832\">If $\\langle {\\mathbf x}, {\\mathbf y} \\rangle = 0$  for all ${\\mathbf x}$ in ${\\mathbb R}^n\\text{,}$ then ${\\mathbf y} = 0\\text{.}$</p></li></ol></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-on-preserves-length\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.7</span></h6><p id=\"p-1833\">The vector ${\\mathbf x} =(3,4)^{\\rm t}$ has length $\\sqrt{3^2 + 4^2} = 5\\text{.}$  We can also see that the orthogonal matrix</p><div class=\"displaymath\">\n\\begin{equation*}\nA=\n\\begin{pmatrix}\n3/5 & -4/5 \\\\\n4/5 & 3/5\n\\end{pmatrix}\n\\end{equation*}\n</div><p>preserves the length of this vector. The vector $A{\\mathbf x} = (-7/5,24/5)^{\\rm t}$ also has length 5.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1834\">Since $\\det(A A^{\\rm t}) = \\det(I) = 1$ and $\\det(A) = \\det( A^{\\rm t} )\\text{,}$ the determinant of any orthogonal matrix is either 1 or $-1\\text{.}$ Consider the column vectors</p><div class=\"displaymath\">\n\\begin{equation*}\n{\\mathbf a}_j =\n\\begin{pmatrix}\na_{1j} \\\\ a_{2j} \\\\ \\vdots \\\\ a_{nj}\n\\end{pmatrix}\n\\end{equation*}\n</div><p>of the orthogonal matrix $A= (a_{ij})\\text{.}$ Since $AA^{\\rm t} = I\\text{,}$ $\\langle {\\mathbf a}_r, {\\mathbf a}_s \\rangle = \\delta_{rs}\\text{,}$ where</p><div class=\"displaymath\">\n\\begin{equation*}\n\\delta_{rs}\n=\n\\left\\{\n\\begin{array}{cc}\n1 & r = s \\\\\n0 & r \\neq s\n\\end{array}\n\\right.\n\\end{equation*}\n</div><p>is the Kronecker delta. Accordingly, column vectors of an orthogonal matrix all have length 1; and the Euclidean inner product of distinct column vectors is zero. Any set of vectors satisfying these properties is called an <dfn class=\"terminology\">orthonormal set</dfn>. Conversely, given an $n \\times n$ matrix $A$ whose columns form an orthonormal set, it follows that $A^{-1} = A^{\\rm t}\\text{.}$</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1835\">We say that a matrix $A$ is <dfn class=\"terminology\">distance-preserving</dfn>, <dfn class=\"terminology\">length-preserving</dfn>, or <dfn class=\"terminology\">inner product-preserving</dfn> when $\\| T{\\mathbf x}- T{\\mathbf y} \\| =\\| {\\mathbf x}- {\\mathbf y} \\|\\text{,}$ $\\| T{\\mathbf x} \\| =\\| {\\mathbf x} \\|\\text{,}$ or $\\langle  T{\\mathbf x}, T{\\mathbf y} \\rangle = \\langle {\\mathbf x},{\\mathbf y} \\rangle\\text{,}$ respectively. The following theorem, which characterizes the orthogonal group, says that these notions are the same.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"theorem-like\" id=\"theorem-orthnormal-matrix\"><h6 class=\"heading\"><span class=\"type\">Theorem</span><span class=\"codenumber\">12.8</span></h6><p id=\"p-1836\">Let $A$ be an $n \\times n$ matrix.  The following statements are equivalent. </p><ol class=\"decimal\"><li id=\"li-427\"><p id=\"p-1837\">The columns of the matrix $A$ form an orthonormal set.</p></li><li id=\"li-428\"><p id=\"p-1838\">$A^{-1} = A^{\\rm t}\\text{.}$</p></li><li id=\"li-429\"><p id=\"p-1839\">For vectors ${\\mathbf x}$ and ${\\mathbf y}\\text{,}$ $\\langle  A{\\mathbf x}, A {\\mathbf y} \\rangle = \\langle  {\\mathbf x}, {\\mathbf y} \\rangle\\text{.}$</p></li><li id=\"li-430\"><p id=\"p-1840\">For vectors ${\\mathbf x}$ and ${\\mathbf y}\\text{,}$ $\\| A{\\mathbf x}- A{\\mathbf y} \\| = \\| {\\mathbf x}- {\\mathbf y} \\|\\text{.}$</p></li><li id=\"li-431\"><p id=\"p-1841\">For any vector ${\\mathbf x}\\text{,}$ $\\| A{\\mathbf x} \\| = \\| {\\mathbf x}\\|\\text{.}$</p></li></ol></article><article class=\"proof\" id=\"proof-77\"><h6 class=\"heading\"><span class=\"type\">Proof</span></h6><p id=\"p-1842\">We have already shown (1) and (2) to be equivalent.</p><p id=\"p-1843\">$(2) \\Rightarrow (3)\\text{.}$</p><div class=\"displaymath\">\n\\begin{align*}\n\\langle A{\\mathbf x}, A{\\mathbf y} \\rangle & = (A {\\mathbf x})^{\\rm t} A {\\mathbf y}\\\\\n& = {\\mathbf x}^{\\rm t} A^{\\rm t} A {\\mathbf y}\\\\\n& = {\\mathbf x}^{\\rm t} {\\mathbf y}\\\\\n& = \\langle {\\mathbf x}, {\\mathbf y} \\rangle.\n\\end{align*}\n</div><p id=\"p-1844\">$(3) \\Rightarrow (2)\\text{.}$ Since</p><div class=\"displaymath\">\n\\begin{align*}\n\\langle {\\mathbf x}, {\\mathbf x} \\rangle & = \\langle A{\\mathbf x}, A{\\mathbf x} \\rangle\\\\\n& = {\\mathbf x}^{\\rm t} A^{\\rm t} A {\\mathbf x}\\\\\n& = \\langle {\\mathbf x}, A^{\\rm t} A{\\mathbf x} \\rangle,\n\\end{align*}\n</div><p>we know that $\\langle {\\mathbf x}, (A^{\\rm t} A - I){\\mathbf x} \\rangle = 0$ for all ${\\mathbf x}\\text{.}$  Therefore, $A^{\\rm t} A -I = 0$ or $A^{-1} = A^{\\rm t}\\text{.}$</p><p id=\"p-1845\">$(3) \\Rightarrow (4)\\text{.}$ If $A$ is inner product-preserving, then $A$ is distance-preserving, since</p><div class=\"displaymath\">\n\\begin{align*}\n\\| A{\\mathbf x} - A{\\mathbf y} \\|^2 & = \\| A({\\mathbf x} - {\\mathbf y}) \\|^2\\\\\n& = \\langle A({\\mathbf x} - {\\mathbf y}), A({\\mathbf x} - {\\mathbf y}) \\rangle\\\\\n& = \\langle {\\mathbf x} - {\\mathbf y}, {\\mathbf x} - {\\mathbf y} \\rangle\\\\\n& = \\| {\\mathbf x} - {\\mathbf y} \\|^2.\n\\end{align*}\n</div><p id=\"p-1846\">$(4) \\Rightarrow (5)\\text{.}$ If $A$ is distance-preserving, then $A$ is length-preserving. Letting ${\\mathbf y} = 0\\text{,}$ we have</p><div class=\"displaymath\">\n\\begin{equation*}\n\\| A{\\mathbf x}\\| = \\| A{\\mathbf x}- A{\\mathbf y} \\| = \\| {\\mathbf x}- {\\mathbf y} \\| = \\| {\\mathbf x} \\|.\n\\end{equation*}\n</div><p id=\"p-1847\">$(5) \\Rightarrow (3)\\text{.}$ We use the following identity to show that length-preserving implies inner product-preserving:</p><div class=\"displaymath\">\n\\begin{equation*}\n\\langle {\\mathbf x}, {\\mathbf y} \\rangle = \\frac{1}{2} \\left[ \\|{\\mathbf x} +{\\mathbf y}\\|^2 - \\|{\\mathbf x}\\|^2 - \\|{\\mathbf y}\\|^2 \\right].\n\\end{equation*}\n</div><p>Observe that</p><div class=\"displaymath\">\n\\begin{align*}\n\\langle A {\\mathbf x}, A {\\mathbf y} \\rangle & = \\frac{1}{2} \\left[ \\|A {\\mathbf x} + A {\\mathbf y} \\|^2 - \\|A {\\mathbf x} \\|^2 -  \\|A {\\mathbf y} \\|^2 \\right]\\\\\n& = \\frac{1}{2} \\left[ \\|A ( {\\mathbf x} + {\\mathbf y} ) \\|^2 - \\|A {\\mathbf x} \\|^2 -  \\|A {\\mathbf y} \\|^2 \\right]\\\\\n& = \\frac{1}{2} \\left[ \\|{\\mathbf x} + {\\mathbf y}\\|^2 - \\|{\\mathbf x}\\|^2 - \\|{\\mathbf y}\\|^2 \\right]\\\\\n& = \\langle {\\mathbf x}, {\\mathbf y} \\rangle.\n\\end{align*}\n</div></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"figure-o2\"><img src=\"images/matrix-o2.svg\" width=\"100%\" alt=\"\" /><figcaption><span class=\"type\">Figure</span><span class=\"codenumber\">12.9</span>$O(2)$ acting on $\\mathbb R^2$</figcaption></figure></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><article class=\"example-like\" id=\"example-o2\"><h6 class=\"heading\"><span class=\"type\">Example</span><span class=\"codenumber\">12.10</span></h6><p id=\"p-1848\">Let us examine the orthogonal group  on ${\\mathbb R}^2$ a bit more closely.  An element $T \\in O(2)$ is determined by its action on ${\\mathbf e}_1 = (1, 0)^{\\rm t}$ and ${\\mathbf e}_2 = (0, 1)^{\\rm t}\\text{.}$ If $T({\\mathbf e}_1) = (a,b)^{\\rm t}\\text{,}$ then $a^2 + b^2 = 1$ and $T({\\mathbf e}_2) = (-b, a)^{\\rm t}\\text{.}$ Hence, $T$ can be represented by</p><div class=\"displaymath\">\n\\begin{equation*}\nA\n=\n\\begin{pmatrix}\na & -b \\\\\nb & a\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\cos \\theta & - \\sin \\theta \\\\\n\\sin \\theta & \\cos \\theta\n\\end{pmatrix},\n\\end{equation*}\n</div><p>where $0 \\leq \\theta \\lt 2 \\pi\\text{.}$ A matrix $T$ in $O(2)$ either reflects or rotates a vector in ${\\mathbb R}^2$ (Figure <a href=\"section-matrix-groups.ipynb#figure-o2\" class=\"xref\" alt=\"Figure 12.9 \" title=\"Figure 12.9 \">12.9</a>). A reflection about the horizontal axis is given by the matrix</p><div class=\"displaymath\">\n\\begin{equation*}\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix},\n\\end{equation*}\n</div><p>whereas a rotation by an angle $\\theta$ in a counterclockwise direction must come from a matrix of the form</p><div class=\"displaymath\">\n\\begin{equation*}\n\\begin{pmatrix}\n\\cos \\theta & \\sin \\theta \\\\\n\\sin \\theta & -\\cos \\theta\n\\end{pmatrix}.\n\\end{equation*}\n</div><p>A reflection about a line $\\ell$ is simply a reflection about the horizontal axis followed by a rotation.  If $\\det A =-1\\text{,}$ then $A$ gives a reflection.</p></article></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><p id=\"p-1849\">Two of the other matrix or matrix-related groups that we will consider are the special orthogonal group  and the group of Euclidean motions. The <dfn class=\"terminology\">special orthogonal group</dfn>, $SO(n)\\text{,}$ is just the intersection of $O(n)$ and $SL_n({\\mathbb R})\\text{;}$ that is, those elements in $O(n)$ with determinant one.  The <dfn class=\"terminology\">Euclidean group</dfn>, $E(n)\\text{,}$ can be written as ordered pairs $(A, {\\mathbf x})\\text{,}$ where $A$ is in $O(n)$ and ${\\mathbf x}$ is in ${\\mathbb R}^n\\text{.}$ We define multiplication by </p><div class=\"displaymath\">\n\\begin{equation*}\n(A, {\\mathbf x}) (B, {\\mathbf y}) = (AB, A {\\mathbf y} +{\\mathbf x}).\n\\end{equation*}\n</div><p>The identity of the group is $(I,{\\mathbf 0})\\text{;}$ the inverse of $(A, {\\mathbf x})$ is $(A^{-1}, -A^{-1} {\\mathbf x})\\text{.}$ In Exercise <a href=\"exercises-matrix.ipynb#exercise-matrix-en-group\" class=\"xref\" alt=\"Exercise 12.3.6 \" title=\"Exercise 12.3.6 \">12.3.6</a>, you are asked to check that $E(n)$ is indeed a group under this operation.</p></div>"]},
{"cell_type":"markdown", "metadata":{}, "source":["<div class=\"mathbook-content\"><figure class=\"figure-like\" id=\"figure-isometries\"><img src=\"images/matrix-r2-translations.svg\" width=\"100%\" alt=\"\" /><figcaption><span class=\"type\">Figure</span><span class=\"codenumber\">12.11</span>Translations in $\\mathbb R^2$</figcaption></figure></div>"]}
],
"nbformat": 4, "nbformat_minor": 0, "metadata": {"kernelspec": {"display_name": "", "name": "sagemath"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "version": "2.7.8"}, "name": "section-matrix-groups.ipynb"}
}